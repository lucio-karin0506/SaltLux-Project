{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1절. 인공지능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2절. 자연어처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3절 자연어처리를 위한 텍스트 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4절. 워드 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TF (Term Frequency)\n",
    "text = \"John likes to watch movies. Mary likes movies too.\\\n",
    "        Mary also likes to watch football games.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'likes', 'to', 'watch', 'movies', 'Mary', 'likes', 'movies', 'too', 'Mary', 'also', 'likes', 'to', 'watch', 'football', 'games']\n"
     ]
    }
   ],
   "source": [
    "words = text.replace('.', '').split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['John', 'Mary', 'also', 'football', 'games', 'likes', 'movies',\n",
      "       'to', 'too', 'watch'], dtype='<U8'), array([1, 2, 1, 1, 1, 3, 2, 2, 1, 2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_count = np.unique(words, return_counts=True)\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'John': 1, 'Mary': 2, 'also': 1, 'football': 1, 'games': 1, 'likes': 3, 'movies': 2, 'to': 2, 'too': 1, 'watch': 2}\n"
     ]
    }
   ],
   "source": [
    "word_to_cnt = {}\n",
    "for word, cnt in zip(*word_count):\n",
    "    word_to_cnt[word] = cnt\n",
    "\n",
    "print(word_to_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TDM (Term Document Matrix)\n",
    "corpus = [\n",
    "    \"John likes to watch movies. Mary likes movies too.\",\n",
    "    \"Mary also likes to watch football games.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 2 1 2 1 1 1]\n",
      " [1 1 1 0 1 1 0 1 0 1]]\n",
      "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer()\n",
    "tdm_array = vector.fit_transform(corpus).toarray()\n",
    "tf_dic = vector.vocabulary_\n",
    "print(tdm_array)\n",
    "print(tf_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>mary</th>\n",
       "      <th>movies</th>\n",
       "      <th>to</th>\n",
       "      <th>too</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   also  football  games  john  likes  mary  movies  to  too  watch\n",
       "0     0         0      0     1      2     1       2   1    1      1\n",
       "1     1         1      1     0      1     1       0   1    0      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tf_dic_sorted = dict(sorted(tf_dic.items(), key=lambda x: x[1]))\n",
    "tdm = pd.DataFrame(tdm_array, columns=tf_dic_sorted.keys())\n",
    "tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>john</th>\n",
       "      <th>likes</th>\n",
       "      <th>to</th>\n",
       "      <th>watch</th>\n",
       "      <th>movies</th>\n",
       "      <th>mary</th>\n",
       "      <th>too</th>\n",
       "      <th>also</th>\n",
       "      <th>football</th>\n",
       "      <th>games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.460629</td>\n",
       "      <td>0.230315</td>\n",
       "      <td>0.647398</td>\n",
       "      <td>0.230315</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.230315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.446101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       john     likes        to     watch    movies      mary       too  \\\n",
       "0  0.000000  0.000000  0.000000  0.323699  0.460629  0.230315  0.647398   \n",
       "1  0.446101  0.446101  0.446101  0.000000  0.317404  0.317404  0.000000   \n",
       "\n",
       "       also  football     games  \n",
       "0  0.230315  0.323699  0.230315  \n",
       "1  0.317404  0.000000  0.317404  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_array = tfidf_vec.fit_transform(corpus).toarray()\n",
    "\n",
    "tfidf_dic = tfidf_vec.vocabulary_\n",
    "tfidf_dic_sorted = dict(sorted(tfidf_dic.items(), key=lambda item: item[1]))\n",
    "\n",
    "tfidf_tdm = pd.DataFrame(tfidf_array, columns=tfidf_dic.keys())\n",
    "tfidf_tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 0.21617142856121063), ('also', 0.09291722625494003), ('too', 0.027057476341724396), ('football', 0.016134677454829216), ('Mary', -0.010840574279427528), ('to', -0.02775036357343197), ('movies', -0.05234673246741295), ('games', -0.059876296669244766), ('watch', -0.111670583486557)]\n",
      "0.064089775\n"
     ]
    }
   ],
   "source": [
    "# 4. Word2Vec\n",
    "corpus = [\"John likes to watch movies. Mary likes movies too\",\n",
    "          \"Mary also likes to watch football games.\"]\n",
    "\n",
    "word_list = []\n",
    "for word in corpus:\n",
    "    word_list.append(word.replace('.', '').split())\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(word_list, sg=0, vector_size=100, window=3, min_count=1)\n",
    "\n",
    "print(model.wv.most_similar('likes'))\n",
    "print(model.wv.similarity('movies', 'games'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\ameli\\\\anaconda3\\\\envs\\\\saltlux_deep_lecture\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Projects/python-workspace/NLP/datasets/ko.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m인공지능\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\saltlux_deep_lecture\\lib\\site-packages\\gensim\\models\\word2vec.py:1942\u001b[0m, in \u001b[0;36mWord2Vec.load\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ae\n\u001b[0;32m   1938\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m   1939\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel load error. Was model saved using code from an older Gensim Version? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1940\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry loading older model using gensim-3.8.3, then re-saving, to restore \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompatibility with current code.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1942\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ae\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\saltlux_deep_lecture\\lib\\site-packages\\gensim\\models\\word2vec.py:1930\u001b[0m, in \u001b[0;36mWord2Vec.load\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;124;03m\"\"\"Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \n\u001b[0;32m   1913\u001b[0m \u001b[38;5;124;03mSee Also\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \n\u001b[0;32m   1928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1930\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(Word2Vec, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Word2Vec):\n\u001b[0;32m   1932\u001b[0m         rethrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\saltlux_deep_lecture\\lib\\site-packages\\gensim\\utils.py:485\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    481\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, fname)\n\u001b[0;32m    483\u001b[0m compress, subname \u001b[38;5;241m=\u001b[39m SaveLoad\u001b[38;5;241m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m--> 485\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m obj\u001b[38;5;241m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m    487\u001b[0m obj\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m, fname\u001b[38;5;241m=\u001b[39mfname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\saltlux_deep_lecture\\lib\\site-packages\\gensim\\utils.py:1460\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \n\u001b[0;32m   1458\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m-> 1460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from 'C:\\\\Users\\\\ameli\\\\anaconda3\\\\envs\\\\saltlux_deep_lecture\\\\lib\\\\site-packages\\\\gensim\\\\models\\\\word2vec.py'>"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('C:/Projects/python-workspace/NLP/datasets/ko.bin')\n",
    "print(model.wv.most_similar('인공지능'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c726b45dd7293eb31a34b8969b40a947eb51be7b196d382e5dff74d4c7ac181"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('saltlux_deep_lecture': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
