{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라벨링 특징 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    1. 영상의 처리는 왼쪽에서 오른쪽으로 그리고 위에서 아래로 화소를 읽으면서 처리, 가장 먼저 마주친 화소에 번호 부여\n",
    "    2. 현재 화소 p에 연결되고 있는 주위 화소에 같은 라벨 붙임\n",
    "    3. 2단계에서 라벨을 붙인 화소에 연결되어 있는 화소에 라벨 붙임\n",
    "    4. 라벨을 붙여야 할 화소가 없어질 때까지 3단계를 반복\n",
    "'''\n",
    "\n",
    "# 현재 주목 화소가 라벨이 있으면 연결되어 있는 주위 8근방 화소에 같은 라벨 붙여줌\n",
    "def labelset(img, xs, ys, label):\n",
    "    height, width = img.shape\n",
    "    img[ys, xs] = label\n",
    "\n",
    "    while True:\n",
    "        cnt = 0\n",
    "        for y in range(1, height-1):\n",
    "            for x in range(1, width-1):\n",
    "                if img[y, x] == label:\n",
    "                    if img[y , x+1] == 255:\n",
    "                        img[y , x+1] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y-1, x+1] == 255:\n",
    "                        img[y-1, x+1] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y-1, x ] == 255:\n",
    "                        img[y-1, x ] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y-1, x-1] == 255:\n",
    "                        img[y-1, x-1] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y , x-1] == 255:\n",
    "                        img[y , x-1] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y+1, x-1] == 255:\n",
    "                        img[y+1, x-1] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y+1, x ] == 255:\n",
    "                        img[y+1, x ] = label; cnt = cnt+1\n",
    "\n",
    "                    if img[y+1, x+1] == 255 :\n",
    "                        img[y+1, x+1] = label; cnt = cnt+1\n",
    "\n",
    "        if cnt == 0:\n",
    "            return (0, img)\n",
    "\n",
    "    return (1, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 화소에 대해 라벨링 수행\n",
    "def labeling(img_in, base=100):\n",
    "    height, width = img_in.shape\n",
    "    img_label = img_in.copy()\n",
    "\n",
    "    label = base # 베이스 값부터 라벨링\n",
    "\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            if img_label[y, x] == 255:\n",
    "                if label >= 255:\n",
    "                    print('error! too many labels!')\n",
    "                    return -1\n",
    "\n",
    "                _, img_label = labelset(img_label, x, y, label)\n",
    "                label = label + 1\n",
    "\n",
    "    cnt = label - base\n",
    "\n",
    "    return img_label, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "객체 수 4\n",
      "100 101 102 103\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('images/shape.png', 0)\n",
    "_, bin_img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "labeled_img, cnt = labeling(bin_img)\n",
    "\n",
    "print(\"객체 수\", cnt)\n",
    "print(labeled_img[80, 80], end=\" \")\n",
    "print(labeled_img[69,173], end=\" \")\n",
    "print(labeled_img[160,190], end=\" \")\n",
    "print(labeled_img[160,60])\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('Labeling', labeled_img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 객체 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OpenCV와 머신러닝을 이용한 필기체 숫자 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 필기체 숫자 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2000)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('images/digits.png', cv2.IMREAD_GRAYSCALE)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "# 20*20 배열로 생성\n",
    "cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]\n",
    "x = np.array(cells)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[:, :].reshape(-1, 400).astype(np.float32)\n",
    "y = np.repeat(np.arange(10), 500)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 머신러닝 분류모형 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9426666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_X, train_y)\n",
    "print(model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 머신러닝 모형 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('number.model', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9426666666666667\n"
     ]
    }
   ],
   "source": [
    "with open('number.model', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 웹 카메라를 이용한 실시간 필기체 숫자 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, bin_img = cv2.threshold(g_img, 110, 255, cv2.THRESH_BINARY_INV)\n",
    "            contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            try:\n",
    "                for contour in contours:\n",
    "                    (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "                    if radius > 5:\n",
    "                        xs, xe = int(x-radius), int(x+radius)\n",
    "                        ys, ye = int(y-radius), int(y+radius)\n",
    "\n",
    "                        cv2.rectangle(bin_img, (xs, ys), (xe, ye), (255, 0, 0), 1)\n",
    "                        roi = bin_img[ys:ye, xs:xe]\n",
    "                        \n",
    "                        dst = cv2.resize(roi, dsize=(50, 50), interpolation=cv2.INTER_AREA)\n",
    "                        dst = cv2.resize(roi, dsize=(16, 16), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                        A = np.zeros((20, 20))\n",
    "                        A[2:-2, 2:-2] = dst[:, :]\n",
    "                        A = A.reshape(-1, 400)\n",
    "\n",
    "                        num = model.predict(A)\n",
    "                        cv2.putText(bin_img, str(num), (xs, ys), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            cv2.imshow('Image', bin_img)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print('No Frame')\n",
    "            break\n",
    "\n",
    "else:\n",
    "    print('Camera not opened')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c726b45dd7293eb31a34b8969b40a947eb51be7b196d382e5dff74d4c7ac181"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('saltlux_deep_lecture': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
