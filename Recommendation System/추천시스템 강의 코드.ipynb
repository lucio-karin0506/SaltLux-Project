{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 기본적인 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age sex  occupation zip_code\n",
       "user_id                              \n",
       "1         24   M  technician    85711\n",
       "2         53   F       other    94043\n",
       "3         23   M      writer    32067\n",
       "4         24   M  technician    43537\n",
       "5         33   F       other    15213"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./dataset/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
    "users = users.set_index('user_id')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release date</th>\n",
       "      <th>video release date</th>\n",
       "      <th>IMDB URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title release date  video release date  \\\n",
       "movie_id                                                       \n",
       "1          Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2          GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3         Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4         Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5            Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                   IMDB URL  unknown  Action  \\\n",
       "movie_id                                                                       \n",
       "1         http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "2         http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "3         http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "4         http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "5         http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "          Adventure  Animation  Children's  Comedy  ...  Fantasy  Film-Noir  \\\n",
       "movie_id                                            ...                       \n",
       "1                 0          1           1       1  ...        0          0   \n",
       "2                 1          0           0       0  ...        0          0   \n",
       "3                 0          0           0       0  ...        0          0   \n",
       "4                 0          0           0       1  ...        0          0   \n",
       "5                 0          0           0       0  ...        0          0   \n",
       "\n",
       "          Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  western  \n",
       "movie_id                                                                     \n",
       "1              0        0        0        0       0         0    0        0  \n",
       "2              0        0        0        0       0         1    0        0  \n",
       "3              0        0        0        0       0         1    0        0  \n",
       "4              0        0        0        0       0         0    0        0  \n",
       "5              0        0        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL',\n",
    "          'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s',\n",
    "          'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
    "          'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller',\n",
    "          'War', 'western']\n",
    "\n",
    "movies = pd.read_csv('./dataset/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "movies = movies.set_index('movie_id')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie_id  rating  timestamp\n",
       "user_id                             \n",
       "196           242       3  881250949\n",
       "186           302       3  891717742\n",
       "22            377       1  878887116\n",
       "244            51       2  880606923\n",
       "166           346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./dataset/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings = ratings.set_index('user_id')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 인기제품 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "814                         Great Day in Harlem, A (1994)\n",
       "1599                        Someone Else's America (1995)\n",
       "1201           Marlene Dietrich: Shadow and Light (1996) \n",
       "1122                       They Made Me a Criminal (1939)\n",
       "1653    Entertaining Angels: The Dorothy Day Story (1996)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best-seller 추천\n",
    "# 전체 사용자의 평점평균을 사용\n",
    "def recom_movie1(n_items):\n",
    "    movie_mean = ratings.groupby(['movie_id'])['rating'].mean()\n",
    "    movie_sort = movie_mean.sort_values(ascending=False)[:n_items]\n",
    "    recom_movies = movies.loc[movie_sort.index]\n",
    "    recommendations = recom_movies['title']\n",
    "    return recommendations\n",
    "\n",
    "recom_movie1(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "814                         Great Day in Harlem, A (1994)\n",
       "1599                        Someone Else's America (1995)\n",
       "1201           Marlene Dietrich: Shadow and Light (1996) \n",
       "1122                       They Made Me a Criminal (1939)\n",
       "1653    Entertaining Angels: The Dorothy Day Story (1996)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recom_movie2(n_items):\n",
    "    movie_mean = ratings.groupby(['movie_id'])['rating'].mean()\n",
    "    return movies.loc[movie_mean.sort_values(ascending=False)[:n_items].index]['title']\n",
    "\n",
    "recom_movie2(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 추천 시스템의 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산\n",
    "import numpy as np\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996007224010567\n"
     ]
    }
   ],
   "source": [
    "# 실제 영화 평점 값과\n",
    "# best-seller 방식으로 구한 예측 값의\n",
    "# rmse 도출\n",
    "rmse = []\n",
    "movie_mean = ratings.groupby(['movie_id'])['rating'].mean()\n",
    "\n",
    "for user in set(ratings.index):\n",
    "    y_true = ratings.loc[user]['rating']\n",
    "    y_pred = movie_mean[ratings.loc[user]['movie_id']]\n",
    "    accuracy = RMSE(y_true, y_pred)\n",
    "    rmse.append(accuracy)\n",
    "\n",
    "print(np.mean(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 사용자 집단별 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tiemstamp\n",
    "ratins = ratings.drop('timestamp', axis=1)\n",
    "\n",
    "movies = movies.reset_index()\n",
    "movies = movies[['movie_id', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratings = ratings.reset_index()\n",
    "x = ratings.copy()\n",
    "y = ratings['user_id']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 별 rmse 계산\n",
    "def score(model):\n",
    "    id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
    "    y_pred = np.array([model(user, movie) for (user, movie) in id_pairs])\n",
    "    y_true = np.array(x_test['rating'])\n",
    "    return RMSE(y_true, y_pred)\n",
    "\n",
    "# train 데이터로 full matrix 구하기\n",
    "rating_matrix = x_train.pivot(index='user_id', columns='movie_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0238991621832114"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 평균으로 예측치 계산하는 기본 모델\n",
    "def best_seller(user_id, movie_id):\n",
    "    train_mean = x_train.groupby('movie_id')['rating'].mean()\n",
    "    try:\n",
    "        rating = train_mean[movie_id]\n",
    "    except:\n",
    "        rating = 3.0\n",
    "    return rating\n",
    "\n",
    "score(best_seller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full matrix를 사용자 데이터와 merge\n",
    "users = users.reset_index()\n",
    "merged_ratings = pd.merge(x_train, users)\n",
    "users = users.set_index('user_id')\n",
    "\n",
    "# gender별 평점평균 계산\n",
    "g_mean = merged_ratings[['movie_id', 'sex', 'rating']].groupby(['movie_id', 'sex'])['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.034398443489634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gender 기준 추천\n",
    "# gender별 평균을 예측치로 돌려주는 함수\n",
    "def cf_gender(user_id, movie_id):\n",
    "    if movie_id in rating_matrix:\n",
    "        gender = users.loc[user_id]['sex']\n",
    "        if gender in g_mean[movie_id]:\n",
    "            gender_rating = g_mean[movie_id][gender]\n",
    "        else:\n",
    "            gender_rating = 3.0\n",
    "\n",
    "    else:\n",
    "        gender_rating = 3.0\n",
    "\n",
    "    return gender_rating\n",
    "\n",
    "score(cf_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 협업 필터링 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 기본 CF 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127072</td>\n",
       "      <td>0.022711</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.290768</td>\n",
       "      <td>0.319740</td>\n",
       "      <td>0.312732</td>\n",
       "      <td>0.266690</td>\n",
       "      <td>0.070433</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346773</td>\n",
       "      <td>0.066398</td>\n",
       "      <td>0.214631</td>\n",
       "      <td>0.164157</td>\n",
       "      <td>0.131266</td>\n",
       "      <td>0.103070</td>\n",
       "      <td>0.229152</td>\n",
       "      <td>0.114776</td>\n",
       "      <td>0.131949</td>\n",
       "      <td>0.324209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120108</td>\n",
       "      <td>0.066896</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.185720</td>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127483</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>0.238432</td>\n",
       "      <td>0.259440</td>\n",
       "      <td>0.171645</td>\n",
       "      <td>0.122343</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.054072</td>\n",
       "      <td>0.087671</td>\n",
       "      <td>0.048119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022711</td>\n",
       "      <td>0.120108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250797</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>0.062717</td>\n",
       "      <td>0.043946</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.073219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041617</td>\n",
       "      <td>0.058156</td>\n",
       "      <td>0.078196</td>\n",
       "      <td>0.074641</td>\n",
       "      <td>0.091856</td>\n",
       "      <td>0.034535</td>\n",
       "      <td>0.159685</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>0.158385</td>\n",
       "      <td>0.034538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059277</td>\n",
       "      <td>0.066896</td>\n",
       "      <td>0.250797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>0.040887</td>\n",
       "      <td>0.053542</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097751</td>\n",
       "      <td>0.118870</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079997</td>\n",
       "      <td>0.078578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.290768</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175392</td>\n",
       "      <td>0.296209</td>\n",
       "      <td>0.140497</td>\n",
       "      <td>0.067496</td>\n",
       "      <td>0.136950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291030</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.075566</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>0.138620</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.171204</td>\n",
       "      <td>0.072635</td>\n",
       "      <td>0.099739</td>\n",
       "      <td>0.244768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id       1         2         3         4         5         6         7    \\\n",
       "user_id                                                                         \n",
       "1        1.000000  0.127072  0.022711  0.059277  0.290768  0.319740  0.312732   \n",
       "2        0.127072  1.000000  0.120108  0.066896  0.040045  0.185720  0.074583   \n",
       "3        0.022711  0.120108  1.000000  0.250797  0.028854  0.062717  0.043946   \n",
       "4        0.059277  0.066896  0.250797  1.000000  0.044420  0.040887  0.053542   \n",
       "5        0.290768  0.040045  0.028854  0.044420  1.000000  0.175392  0.296209   \n",
       "\n",
       "user_id       8         9         10   ...       934       935       936  \\\n",
       "user_id                                ...                                 \n",
       "1        0.266690  0.070433  0.271318  ...  0.346773  0.066398  0.214631   \n",
       "2        0.004358  0.083743  0.116722  ...  0.127483  0.136337  0.238432   \n",
       "3        0.060027  0.078141  0.073219  ...  0.041617  0.058156  0.078196   \n",
       "4        0.108960  0.074074  0.044267  ...  0.069959  0.000000  0.097751   \n",
       "5        0.140497  0.067496  0.136950  ...  0.291030  0.077253  0.075566   \n",
       "\n",
       "user_id       937       938       939       940       941       942       943  \n",
       "user_id                                                                        \n",
       "1        0.164157  0.131266  0.103070  0.229152  0.114776  0.131949  0.324209  \n",
       "2        0.259440  0.171645  0.122343  0.204004  0.054072  0.087671  0.048119  \n",
       "3        0.074641  0.091856  0.034535  0.159685  0.072078  0.158385  0.034538  \n",
       "4        0.118870  0.010639  0.000000  0.094002  0.000000  0.079997  0.078578  \n",
       "5        0.049234  0.138620  0.046403  0.171204  0.072635  0.099739  0.244768  \n",
       "\n",
       "[5 rows x 943 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set의 모든 가능한 사용자 pair의 Cosine similarities 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "user_similarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0179452999628942"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 영화의 movie_id 가중평균 rating을 계산\n",
    "# 가중치는 주어진 사용자와 다른 사용자 간의 유사도(user_similarity)\n",
    "def CF_simple(user_id, movie_id):\n",
    "    if movie_id in rating_matrix:\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        movie_ratings = rating_matrix[movie_id].copy()\n",
    "\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.dropna()\n",
    "\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "        mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "\n",
    "    else:\n",
    "        mean_rating = 3.0\n",
    "    \n",
    "    return mean_rating\n",
    "\n",
    "# 정확도 계산\n",
    "score(CF_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 이웃을 고려한 CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 별 rmse 계산 => KNN 모델 평가용\n",
    "def score_KNN(model, neighbor_size=0):\n",
    "    id_pairs = zip(x_test['user_id'], x_test['movie_id'])\n",
    "    y_pred = np.array([model(user, movie, neighbor_size) for (user, movie) in id_pairs])\n",
    "    y_true = np.array(x_test['rating'])\n",
    "    return RMSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0086487677251181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neighbor size를 정해서 예측치 계산하는 함수\n",
    "def cf_knn(user_id, movie_id, neighbor_size=0):\n",
    "    if movie_id in rating_matrix:\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        movie_ratings = rating_matrix[movie_id].copy()\n",
    "\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "\n",
    "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "\n",
    "        # neighbor size가 지정되지 않은 경우\n",
    "        if neighbor_size == 0:\n",
    "            mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "\n",
    "        # 지정된 경우\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "\n",
    "                mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "\n",
    "            else:\n",
    "                mean_rating = 3.0\n",
    "\n",
    "    else:\n",
    "        mean_rating = 3.0\n",
    "\n",
    "    return mean_rating\n",
    "\n",
    "score_KNN(cf_knn, neighbor_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "1293                     Ayn Rand: A Sense of Life (1997)\n",
       "1467                                     Cure, The (1995)\n",
       "1189                              That Old Feeling (1997)\n",
       "1500    Prisoner of the Mountains (Kavkazsky Plennik) ...\n",
       "318                       Everyone Says I Love You (1996)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 사용자에 대해 추천 받기\n",
    "# 전체 데이터로 full matrix와 cosine similarity 구하기\n",
    "rating_matrix = ratings.pivot_table(values='rating', index='user_id', columns='movie_id')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "def recom_movie(user_id, n_items, neighbor_size=30):\n",
    "    user_movie = rating_matrix.loc[user_id].copy()\n",
    "    for movie in rating_matrix:\n",
    "        if pd.notnull(user_movie.loc[movie]):\n",
    "            user_movie.loc[movie] = 0\n",
    "        else:\n",
    "            user_movie.loc[movie] = cf_knn(user_id, movie, neighbor_size)\n",
    "    \n",
    "    movie_sort = user_movie.sort_values(ascending=False)[:n_items]\n",
    "    recom_movies = movies.loc[movie_sort.index]\n",
    "    recommendations = recom_movies['title']\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "recom_movie(user_id=2, n_items=5, neighbor_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 최적의 이웃 크기 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor size = 10 : RMSE = 1.0249\n",
      "Neighbor size = 20 : RMSE = 1.0110\n",
      "Neighbor size = 30 : RMSE = 1.0086\n",
      "Neighbor size = 40 : RMSE = 1.0090\n",
      "Neighbor size = 50 : RMSE = 1.0096\n",
      "Neighbor size = 60 : RMSE = 1.0099\n"
     ]
    }
   ],
   "source": [
    "# 최적의 neighbor size 구하기\n",
    "# train set으로 full matrix와 cosine similarity 구하기\n",
    "rating_matrix = x_train.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "for neighbor_size in [10, 20, 30, 40, 50, 60]:\n",
    "    print(\"Neighbor size = %d : RMSE = %.4f\"%(neighbor_size, score_KNN(cf_knn, neighbor_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 사용자의 평가경향을 고려한 CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.657987422010662"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 유저의 rating 평균과 영화의 평점편차 계산\n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T\n",
    "\n",
    "def CF_knn_bias(user_id, movie_id, neighbor_size=0):\n",
    "    if movie_id in rating_bias:\n",
    "        sim_scores = user_similarity[user_id].copy()\n",
    "        movie_ratings = rating_matrix[movie_id].copy()\n",
    "\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "\n",
    "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "\n",
    "        # neighbor size 지정되지 않은 경우\n",
    "        if neighbor_size == 0:\n",
    "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "\n",
    "        # 지정된 경우\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                \n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "\n",
    "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "\n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "score_KNN(CF_knn_bias, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 그 외의 CF 정확도 개선 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415904217118449"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자별 공통 평가 수 계산\n",
    "rating_binary1 = np.array((rating_matrix > 0).astype(float))\n",
    "rating_binary2 = rating_binary1.T\n",
    "\n",
    "counts = np.dot(rating_binary1, rating_binary2)\n",
    "counts = pd.DataFrame(counts, index=rating_matrix.index, columns=rating_matrix.index).fillna(0)\n",
    "\n",
    "def CF_knn_bias_sig(user_id, movie_id, neighbor_size=0):\n",
    "    if movie_id in rating_bias:\n",
    "\n",
    "        # 현 user와 다른 사용자 간의 유사도 가져오기\n",
    "        sim_scores = user_similarity[user_id]\n",
    "\n",
    "        # 현 movie의 평점편차 가져오기\n",
    "        movie_ratings = rating_bias[movie_id]\n",
    "\n",
    "        # 현 movie에 대한 rating이 없는 사용자 표시\n",
    "        no_rating = movie_ratings.isnull()\n",
    "\n",
    "        # 현 사용자와 다른 사용자간 공통 평가 아이템 수 가져오기 \n",
    "        common_counts = counts[user_id]\n",
    "\n",
    "        # 공통으로 평가한 영화의 수가 SIG_LEVEL보다 낮은 사용자 표시\n",
    "        low_significance = common_counts < SIG_LEVEL\n",
    "\n",
    "        # 평가를 안 하였거나, SIG_LEVEL이 기준 이하인 user 제거\n",
    "        none_rating_idx = movie_ratings[no_rating | low_significance].index\n",
    "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "\n",
    "        if neighbor_size == 0:\n",
    "            # 편차로 예측값(편차 예측값) 계산\n",
    "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "            # 편차 예측값에 현 사용자의 평균 더하기\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "\n",
    "        else:\n",
    "            # 해당 영화를 평가한 사용자가 최소 MIN_RATINGS 이상인 경우에만 계산            \n",
    "            if len(sim_scores) > MIN_RATINGS:\n",
    "\n",
    "                # 지정된 neighbor size 값과 해당 영화를 평가한 총사용자 수 중 작은 것으로 결정\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "\n",
    "                # array로 바꾸기 (argsort를 사용하기 위함)\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "\n",
    "                # 유사도를 순서대로 정렬\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "\n",
    "                # 유사도와 rating을 neighbor size만큼 받기\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "\n",
    "                # 편차로 예측치 계산\n",
    "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "\n",
    "                # 예측값에 현 사용자의 평균 더하기\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "\n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "SIG_LEVEL = 3\n",
    "MIN_RATINGS = 2\n",
    "score_KNN(CF_knn_bias_sig, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 사용자 기반 CF와 아이템 기반 CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터로 Full matrix 구하기  \n",
    "rating_matrix = x_train.pivot(index='user_id', columns='movie_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set의 모든 가능한 아이템 pair의 Cosine similarities 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "rating_matrix_t = np.transpose(rating_matrix)\n",
    "matrix_dummy = rating_matrix_t.copy().fillna(0)\n",
    "item_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "item_similarity = pd.DataFrame(item_similarity, index=rating_matrix_t.index, \n",
    "                               columns=rating_matrix_t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0146934549808586"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 영화의 (movie_id) 가중평균 rating을 계산하는 함수, \n",
    "# 가중치는 주어진 아이템과 다른 아이템 간의 유사도(item_similarity)\n",
    "def CF_IBCF(user_id, movie_id):\n",
    "    if movie_id in item_similarity:      # 현재 영화가 train set에 있는지 확인\n",
    "\n",
    "        # 현재 영화와 다른 영화의 similarity 값 가져오기\n",
    "        sim_scores = item_similarity[movie_id]\n",
    "\n",
    "        # 현 사용자의 모든 rating 값 가져오기\n",
    "        user_rating = rating_matrix_t[user_id]\n",
    "\n",
    "        # 사용자가 평가하지 않은 영화 index 가져오기\n",
    "        non_rating_idx = user_rating[user_rating.isnull()].index\n",
    "\n",
    "        # 사용자가 평가하지 않은 영화 제거\n",
    "        user_rating = user_rating.dropna()\n",
    "\n",
    "        # 사용자가 평가하지 않은 영화의 similarity 값 제거\n",
    "        sim_scores = sim_scores.drop(non_rating_idx)\n",
    "\n",
    "        # 현 영화에 대한 예상 rating 계산, 가중치는 현 영화와 사용자가 평가한 영화의 유사도\n",
    "        mean_rating = np.dot(sim_scores, user_rating) / sim_scores.sum()\n",
    "    else:\n",
    "        mean_rating = 3.0\n",
    "        \n",
    "    return mean_rating\n",
    "\n",
    "# 정확도 계산\n",
    "score(CF_IBCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MF 기반 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 SGD를 사용한 MF 기본 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./dataset/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MF class\n",
    "class MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True) -> None:\n",
    "        self.R = np.array(ratings)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    def train(self):\n",
    "        # user, item feature matrix 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # bias terms 초기화\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # training samples lists\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # SGD를 이용한 R matrix 값 갱신 수행\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1, rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print('Iteration: %d ; Train RMSE = %.4f'%(i+1, rmse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    # rating prediction for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # SGD\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9585\n",
      "Iteration: 20 ; Train RMSE = 0.9374\n",
      "Iteration: 30 ; Train RMSE = 0.9281\n",
      "Iteration: 40 ; Train RMSE = 0.9226\n",
      "Iteration: 50 ; Train RMSE = 0.9185\n",
      "Iteration: 60 ; Train RMSE = 0.9148\n",
      "Iteration: 70 ; Train RMSE = 0.9103\n",
      "Iteration: 80 ; Train RMSE = 0.9043\n",
      "Iteration: 90 ; Train RMSE = 0.8959\n",
      "Iteration: 100 ; Train RMSE = 0.8848\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 사용 MF\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 train/test 분리 MF 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test dataset\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New MF class for training & testing\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Surprise 패키지 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Surprise 기본 활용 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 필요한 Surprise 알고리즘 불러오기\n",
    "from surprise import BaselineOnly \n",
    "from surprise import KNNWithMeans\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import os\n",
    "\n",
    "file_path = os.path.expanduser('./surprise_data/ml-100k/u.data')\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9703034240555881"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.5)\n",
    "\n",
    "algo = KNNWithMeans()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 알고리즘 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.9550\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9703\n",
      "RMSE: 0.9597\n",
      "RMSE: 0.9412\n"
     ]
    }
   ],
   "source": [
    "# compare algorithms\n",
    "algorithms = [BaselineOnly, KNNWithMeans, SVD, SVDpp]\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "for option in algorithms:\n",
    "    algo = option()\n",
    "    names.append(option.__name__) # 알고리즘 이름\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    results.append(accuracy.rmse(predictions))\n",
    "\n",
    "names = np.array(names)\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94116791, 0.95502607, 0.95966445, 0.97030342])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.argsort(results)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(names[index], results[index])\n",
    "results[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 알고리즘 옵션 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9703841087419602"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 알고리즘 옵션 변경, 정확도 계산\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "\n",
    "algo = KNNWithMeans(k=30, sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 다양한 조건의 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9819\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9717\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9704\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9701\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9701\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10, 0.9818706950416946],\n",
       " [20, 0.9716698867134536],\n",
       " [30, 0.9703841087419602],\n",
       " [40, 0.9701247487287492],\n",
       " [50, 0.9700565896462067],\n",
       " [60, 0.9700885841390458]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다양한 neighbor size 비교\n",
    "result = []\n",
    "for neighbor_size in (10, 20, 30, 40, 50, 60):\n",
    "    algo = KNNWithMeans(k=neighbor_size, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    result.append([neighbor_size, accuracy.rmse(predictions)])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9251262313457717\n",
      "{'k': 25, 'sim_options': {'name': 'pearson_baseline', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# KNN 다양한 파라미터 비교\n",
    "param_grid = {'k': [5, 10, 15, 25],\n",
    "              'sim_options': {'name': ['pearson_baseline', 'cosine'],\n",
    "                              'user_based': [True, False]}\n",
    "              }\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=4)\n",
    "gs.fit(data)\n",
    "\n",
    "# 최적 RMSE 출력\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# 최적 RMSE의 parameter\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133225078810472\n",
      "{'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# SVD 다양한 파라메터 비교\n",
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_epochs': [70, 80, 90],\n",
    "              'lr_all': [0.005, 0.006, 0.007],\n",
    "              'reg_all': [0.05, 0.07, 0.1]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=4)\n",
    "gs.fit(data)\n",
    "\n",
    "# 최적 RMSE 출력\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# 최적 RMSE의 parameter\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 외부데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9469055309457518"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일에서 불러오기\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./dataset/u.data', names=r_cols, sep='\\t', encoding='latin-1')\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "# Train/Test 분리 \n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# 정확도 계산 \n",
    "algo = KNNWithMeans()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 딥러닝을 사용한 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Keras로 MF 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# csv 파일에서 불러오기\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./dataset/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 초기화 \n",
    "K = 200                             # Latent factor 수 \n",
    "mu = ratings_train.rating.mean()    # 전체 평균 \n",
    "M = ratings.user_id.max() + 1       # Number of users\n",
    "N = ratings.movie_id.max() + 1      # Number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining RMSE measure\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model\n",
    "user = Input(shape=(1, ))\n",
    "item = Input(shape=(1, ))\n",
    "\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)\n",
    "\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)\n",
    "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 1, 200)       188800      ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 1, 200)       336600      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1, 1)         0           ['embedding_4[0][0]',            \n",
      "                                                                  'embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 1, 1)         944         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 1, 1)         1683        ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1, 1)         0           ['dot_1[0][0]',                  \n",
      "                                                                  'embedding_6[0][0]',            \n",
      "                                                                  'embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1)            0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 528,027\n",
      "Trainable params: 528,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# R = Dot(axes=2) ([P_embedding, Q_embedding)\n",
    "R = layers.dot([P_embedding, Q_embedding], axes=2)\n",
    "R = layers.add([R, user_bias, item_bias])\n",
    "R = Flatten()(R)\n",
    "\n",
    "# model setting\n",
    "model = Model(inputs=[user, item], outputs=R)\n",
    "model.compile(loss=RMSE, optimizer=SGD(), metrics=[RMSE])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 5.2823 - RMSE: 1.1236 - val_loss: 5.0473 - val_RMSE: 1.1281\n",
      "Epoch 2/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 4.8204 - RMSE: 1.1217 - val_loss: 4.6120 - val_RMSE: 1.1262\n",
      "Epoch 3/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 4.4094 - RMSE: 1.1197 - val_loss: 4.2249 - val_RMSE: 1.1244\n",
      "Epoch 4/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 4.0440 - RMSE: 1.1179 - val_loss: 3.8806 - val_RMSE: 1.1228\n",
      "Epoch 5/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 3.7191 - RMSE: 1.1164 - val_loss: 3.5745 - val_RMSE: 1.1213\n",
      "Epoch 6/60\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 3.4302 - RMSE: 1.1149 - val_loss: 3.3022 - val_RMSE: 1.1198\n",
      "Epoch 7/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 3.1732 - RMSE: 1.1135 - val_loss: 3.0601 - val_RMSE: 1.1185\n",
      "Epoch 8/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.9446 - RMSE: 1.1121 - val_loss: 2.8448 - val_RMSE: 1.1173\n",
      "Epoch 9/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.7414 - RMSE: 1.1110 - val_loss: 2.6533 - val_RMSE: 1.1162\n",
      "Epoch 10/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.5606 - RMSE: 1.1098 - val_loss: 2.4830 - val_RMSE: 1.1151\n",
      "Epoch 11/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.3997 - RMSE: 1.1087 - val_loss: 2.3315 - val_RMSE: 1.1142\n",
      "Epoch 12/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2569 - RMSE: 1.1078 - val_loss: 2.1968 - val_RMSE: 1.1133\n",
      "Epoch 13/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.1297 - RMSE: 1.1069 - val_loss: 2.0770 - val_RMSE: 1.1124\n",
      "Epoch 14/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.0167 - RMSE: 1.1061 - val_loss: 1.9705 - val_RMSE: 1.1116\n",
      "Epoch 15/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.9161 - RMSE: 1.1053 - val_loss: 1.8758 - val_RMSE: 1.1109\n",
      "Epoch 16/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.8266 - RMSE: 1.1045 - val_loss: 1.7915 - val_RMSE: 1.1102\n",
      "Epoch 17/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.7471 - RMSE: 1.1039 - val_loss: 1.7166 - val_RMSE: 1.1096\n",
      "Epoch 18/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.6764 - RMSE: 1.1033 - val_loss: 1.6500 - val_RMSE: 1.1090\n",
      "Epoch 19/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.6136 - RMSE: 1.1028 - val_loss: 1.5907 - val_RMSE: 1.1084\n",
      "Epoch 20/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.5575 - RMSE: 1.1021 - val_loss: 1.5380 - val_RMSE: 1.1079\n",
      "Epoch 21/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.5078 - RMSE: 1.1016 - val_loss: 1.4911 - val_RMSE: 1.1074\n",
      "Epoch 22/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.4635 - RMSE: 1.1011 - val_loss: 1.4494 - val_RMSE: 1.1070\n",
      "Epoch 23/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.4243 - RMSE: 1.1008 - val_loss: 1.4124 - val_RMSE: 1.1066\n",
      "Epoch 24/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.3892 - RMSE: 1.1003 - val_loss: 1.3794 - val_RMSE: 1.1062\n",
      "Epoch 25/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.3582 - RMSE: 1.1000 - val_loss: 1.3501 - val_RMSE: 1.1058\n",
      "Epoch 26/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.3304 - RMSE: 1.0996 - val_loss: 1.3240 - val_RMSE: 1.1055\n",
      "Epoch 27/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.3057 - RMSE: 1.0991 - val_loss: 1.3008 - val_RMSE: 1.1052\n",
      "Epoch 28/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.2839 - RMSE: 1.0989 - val_loss: 1.2802 - val_RMSE: 1.1049\n",
      "Epoch 29/60\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 1.2646 - RMSE: 1.0987 - val_loss: 1.2619 - val_RMSE: 1.1046\n",
      "Epoch 30/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.2470 - RMSE: 1.0982 - val_loss: 1.2456 - val_RMSE: 1.1043\n",
      "Epoch 31/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.2317 - RMSE: 1.0980 - val_loss: 1.2311 - val_RMSE: 1.1041\n",
      "Epoch 32/60\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 1.2181 - RMSE: 1.0978 - val_loss: 1.2182 - val_RMSE: 1.1038\n",
      "Epoch 33/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.2058 - RMSE: 1.0975 - val_loss: 1.2067 - val_RMSE: 1.1036\n",
      "Epoch 34/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.1951 - RMSE: 1.0974 - val_loss: 1.1965 - val_RMSE: 1.1034\n",
      "Epoch 35/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1853 - RMSE: 1.0971 - val_loss: 1.1874 - val_RMSE: 1.1032\n",
      "Epoch 36/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.1769 - RMSE: 1.0970 - val_loss: 1.1793 - val_RMSE: 1.1031\n",
      "Epoch 37/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1692 - RMSE: 1.0968 - val_loss: 1.1722 - val_RMSE: 1.1029\n",
      "Epoch 38/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1626 - RMSE: 1.0968 - val_loss: 1.1658 - val_RMSE: 1.1028\n",
      "Epoch 39/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1563 - RMSE: 1.0964 - val_loss: 1.1601 - val_RMSE: 1.1026\n",
      "Epoch 40/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1511 - RMSE: 1.0964 - val_loss: 1.1551 - val_RMSE: 1.1025\n",
      "Epoch 41/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1462 - RMSE: 1.0962 - val_loss: 1.1506 - val_RMSE: 1.1024\n",
      "Epoch 42/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1420 - RMSE: 1.0960 - val_loss: 1.1466 - val_RMSE: 1.1022\n",
      "Epoch 43/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.1383 - RMSE: 1.0960 - val_loss: 1.1430 - val_RMSE: 1.10210s - - ETA: 0s - loss: 1.1388 - RMSE: \n",
      "Epoch 44/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1348 - RMSE: 1.0958 - val_loss: 1.1399 - val_RMSE: 1.1020\n",
      "Epoch 45/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1319 - RMSE: 1.0958 - val_loss: 1.1371 - val_RMSE: 1.1019\n",
      "Epoch 46/60\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 1.1292 - RMSE: 1.0956 - val_loss: 1.1346 - val_RMSE: 1.1018\n",
      "Epoch 47/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1270 - RMSE: 1.0957 - val_loss: 1.1324 - val_RMSE: 1.1018\n",
      "Epoch 48/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1248 - RMSE: 1.0955 - val_loss: 1.1304 - val_RMSE: 1.1017\n",
      "Epoch 49/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1230 - RMSE: 1.0955 - val_loss: 1.1286 - val_RMSE: 1.1016\n",
      "Epoch 50/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1214 - RMSE: 1.0954 - val_loss: 1.1271 - val_RMSE: 1.1015\n",
      "Epoch 51/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1198 - RMSE: 1.0953 - val_loss: 1.1257 - val_RMSE: 1.1015\n",
      "Epoch 52/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1184 - RMSE: 1.0951 - val_loss: 1.1244 - val_RMSE: 1.1014\n",
      "Epoch 53/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1172 - RMSE: 1.0950 - val_loss: 1.1233 - val_RMSE: 1.1014\n",
      "Epoch 54/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1162 - RMSE: 1.0950 - val_loss: 1.1224 - val_RMSE: 1.1013\n",
      "Epoch 55/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1154 - RMSE: 1.0951 - val_loss: 1.1215 - val_RMSE: 1.1013\n",
      "Epoch 56/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1144 - RMSE: 1.0949 - val_loss: 1.1207 - val_RMSE: 1.1012\n",
      "Epoch 57/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1138 - RMSE: 1.0949 - val_loss: 1.1200 - val_RMSE: 1.1012\n",
      "Epoch 58/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1131 - RMSE: 1.0948 - val_loss: 1.1194 - val_RMSE: 1.1011\n",
      "Epoch 59/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1126 - RMSE: 1.0949 - val_loss: 1.1189 - val_RMSE: 1.1011\n",
      "Epoch 60/60\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 1.1120 - RMSE: 1.0947 - val_loss: 1.1184 - val_RMSE: 1.1011\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "result = model.fit(\n",
    "    x=[ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "    y=ratings_train.rating.values - mu,\n",
    "    epochs=60,\n",
    "    batch_size=256,\n",
    "    validation_data=(\n",
    "        [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "        ratings_test.rating.values - mu\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(result.history['RMSE'], label=\"Train RMSE\")\n",
    "plt.plot(result.history['val_RMSE'], label=\"Test RMSE\")\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals: \n",
      "       user_id  movie_id  rating\n",
      "62989      764        28       4\n",
      "5925        86       286       3\n",
      "59050      437       450       3\n",
      "77059      643       685       3\n",
      "81909      654       588       4\n",
      "12645      244       135       4\n",
      "\n",
      "Predictions: \n",
      "[[3.5830245]\n",
      " [3.5631194]\n",
      " [3.5060272]\n",
      " [3.5351927]\n",
      " [3.5561297]\n",
      " [3.5839052]]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "user_ids = ratings_test.user_id.values[0:6]\n",
    "movie_ids = ratings_test.movie_id.values[0:6]\n",
    "\n",
    "predictions = model.predict([user_ids, movie_ids]) + mu\n",
    "\n",
    "print(f'Actuals: \\n{ratings_test[0:6]}')\n",
    "print()\n",
    "print(f'Predictions: \\n{predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1023434902821574"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE check\n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "user_ids = ratings_test.user_id.values\n",
    "movie_ids = ratings_test.movie_id.values\n",
    "\n",
    "y_pred = model.predict([user_ids, movie_ids]) + mu\n",
    "y_pred = np.ravel(y_pred, order='C')\n",
    "y_true = np.array(ratings_test.rating)\n",
    "\n",
    "RMSE2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 딥러닝을 적용한 추천 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model\n",
    "user = Input(shape=(1, ))\n",
    "item = Input(shape=(1, ))\n",
    "\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)\n",
    "\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)\n",
    "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)\n",
    "\n",
    "# Concatenate layers\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "\n",
    "P_embedding = Flatten()(P_embedding)\n",
    "Q_embedding = Flatten()(Q_embedding)\n",
    "user_bias = Flatten()(user_bias)\n",
    "item_bias = Flatten()(item_bias)\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 1, 200)       188800      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 1, 200)       336600      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)       (None, 1, 1)         944         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 1, 1)         1683        ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 200)          0           ['embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 200)          0           ['embedding_9[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 1)            0           ['embedding_10[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 1)            0           ['embedding_11[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 402)          0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         825344      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2048)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          524544      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            257         ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,878,172\n",
      "Trainable params: 1,878,172\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "R = Dense(2048)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(256)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(1)(R)\n",
    "\n",
    "model = Model(inputs=[user, item], outputs=R)\n",
    "model.compile(\n",
    "  loss=RMSE,\n",
    "  optimizer=SGD(),\n",
    "  #optimizer=Adamax(),\n",
    "  metrics=[RMSE]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 5.3914 - RMSE: 1.1227 - val_loss: 5.2710 - val_RMSE: 1.1279\n",
      "Epoch 2/65\n",
      "147/147 [==============================] - 6s 42ms/step - loss: 5.1459 - RMSE: 1.1217 - val_loss: 5.0330 - val_RMSE: 1.1264\n",
      "Epoch 3/65\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 4.9147 - RMSE: 1.1195 - val_loss: 4.8084 - val_RMSE: 1.1248\n",
      "Epoch 4/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 4.6966 - RMSE: 1.1185 - val_loss: 4.5967 - val_RMSE: 1.1234\n",
      "Epoch 5/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 4.4907 - RMSE: 1.1167 - val_loss: 4.3971 - val_RMSE: 1.1219\n",
      "Epoch 6/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 4.2966 - RMSE: 1.1149 - val_loss: 4.2086 - val_RMSE: 1.1202\n",
      "Epoch 7/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 4.1136 - RMSE: 1.1136 - val_loss: 4.0308 - val_RMSE: 1.1185\n",
      "Epoch 8/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 3.9406 - RMSE: 1.1114 - val_loss: 3.8631 - val_RMSE: 1.1167\n",
      "Epoch 9/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 3.7774 - RMSE: 1.1095 - val_loss: 3.7044 - val_RMSE: 1.1146\n",
      "Epoch 10/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 3.6232 - RMSE: 1.1072 - val_loss: 3.5546 - val_RMSE: 1.1122\n",
      "Epoch 11/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 3.4774 - RMSE: 1.1045 - val_loss: 3.4132 - val_RMSE: 1.1098\n",
      "Epoch 12/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 3.3395 - RMSE: 1.1016 - val_loss: 3.2792 - val_RMSE: 1.1067\n",
      "Epoch 13/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 3.2090 - RMSE: 1.0985 - val_loss: 3.1522 - val_RMSE: 1.1031\n",
      "Epoch 14/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 3.0854 - RMSE: 1.0946 - val_loss: 3.0319 - val_RMSE: 1.0991\n",
      "Epoch 15/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 2.9680 - RMSE: 1.0901 - val_loss: 2.9179 - val_RMSE: 1.0947\n",
      "Epoch 16/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 2.8567 - RMSE: 1.0849 - val_loss: 2.8095 - val_RMSE: 1.0894\n",
      "Epoch 17/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 2.7508 - RMSE: 1.0795 - val_loss: 2.7065 - val_RMSE: 1.0836\n",
      "Epoch 18/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 2.6501 - RMSE: 1.0731 - val_loss: 2.6084 - val_RMSE: 1.0769\n",
      "Epoch 19/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 2.5541 - RMSE: 1.0661 - val_loss: 2.5148 - val_RMSE: 1.0695\n",
      "Epoch 20/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 2.4625 - RMSE: 1.0579 - val_loss: 2.4259 - val_RMSE: 1.0617\n",
      "Epoch 21/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 2.3753 - RMSE: 1.0494 - val_loss: 2.3411 - val_RMSE: 1.0532\n",
      "Epoch 22/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 2.2920 - RMSE: 1.0406 - val_loss: 2.2603 - val_RMSE: 1.0443\n",
      "Epoch 23/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 2.2128 - RMSE: 1.0308 - val_loss: 2.1837 - val_RMSE: 1.0355\n",
      "Epoch 24/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 2.1376 - RMSE: 1.0214 - val_loss: 2.1110 - val_RMSE: 1.0266\n",
      "Epoch 25/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 2.0664 - RMSE: 1.0123 - val_loss: 2.0422 - val_RMSE: 1.0179\n",
      "Epoch 26/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.9991 - RMSE: 1.0032 - val_loss: 1.9775 - val_RMSE: 1.0100\n",
      "Epoch 27/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.9354 - RMSE: 0.9948 - val_loss: 1.9163 - val_RMSE: 1.0023\n",
      "Epoch 28/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 1.8757 - RMSE: 0.9870 - val_loss: 1.8590 - val_RMSE: 0.9955\n",
      "Epoch 29/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.8195 - RMSE: 0.9798 - val_loss: 1.8051 - val_RMSE: 0.9893\n",
      "Epoch 30/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.7666 - RMSE: 0.9731 - val_loss: 1.7547 - val_RMSE: 0.9840\n",
      "Epoch 31/65\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 1.7172 - RMSE: 0.9676 - val_loss: 1.7072 - val_RMSE: 0.9791\n",
      "Epoch 32/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.6708 - RMSE: 0.9628 - val_loss: 1.6629 - val_RMSE: 0.9749\n",
      "Epoch 33/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 1.6270 - RMSE: 0.9582 - val_loss: 1.6211 - val_RMSE: 0.9710\n",
      "Epoch 34/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.5863 - RMSE: 0.9540 - val_loss: 1.5822 - val_RMSE: 0.9680\n",
      "Epoch 35/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.5477 - RMSE: 0.9502 - val_loss: 1.5451 - val_RMSE: 0.9647\n",
      "Epoch 36/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.5117 - RMSE: 0.9475 - val_loss: 1.5108 - val_RMSE: 0.9623\n",
      "Epoch 37/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.4776 - RMSE: 0.9442 - val_loss: 1.4812 - val_RMSE: 0.9629\n",
      "Epoch 38/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 1.4458 - RMSE: 0.9415 - val_loss: 1.4477 - val_RMSE: 0.9578\n",
      "Epoch 39/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.4157 - RMSE: 0.9392 - val_loss: 1.4213 - val_RMSE: 0.9583\n",
      "Epoch 40/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.3875 - RMSE: 0.9371 - val_loss: 1.3922 - val_RMSE: 0.9545\n",
      "Epoch 41/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.3609 - RMSE: 0.9353 - val_loss: 1.3663 - val_RMSE: 0.9526\n",
      "Epoch 42/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.3359 - RMSE: 0.9335 - val_loss: 1.3423 - val_RMSE: 0.9511\n",
      "Epoch 43/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.3125 - RMSE: 0.9319 - val_loss: 1.3200 - val_RMSE: 0.9501\n",
      "Epoch 44/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.2904 - RMSE: 0.9308 - val_loss: 1.2985 - val_RMSE: 0.9487\n",
      "Epoch 45/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.2695 - RMSE: 0.9291 - val_loss: 1.2786 - val_RMSE: 0.9478\n",
      "Epoch 46/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.2500 - RMSE: 0.9280 - val_loss: 1.2601 - val_RMSE: 0.9472\n",
      "Epoch 47/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.2315 - RMSE: 0.9269 - val_loss: 1.2433 - val_RMSE: 0.9473\n",
      "Epoch 48/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.2141 - RMSE: 0.9261 - val_loss: 1.2256 - val_RMSE: 0.9455\n",
      "Epoch 49/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1979 - RMSE: 0.9252 - val_loss: 1.2100 - val_RMSE: 0.9450\n",
      "Epoch 50/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1825 - RMSE: 0.9246 - val_loss: 1.1951 - val_RMSE: 0.9443\n",
      "Epoch 51/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1682 - RMSE: 0.9242 - val_loss: 1.1810 - val_RMSE: 0.9436\n",
      "Epoch 52/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.1545 - RMSE: 0.9235 - val_loss: 1.1685 - val_RMSE: 0.9438\n",
      "Epoch 53/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.1417 - RMSE: 0.9229 - val_loss: 1.1570 - val_RMSE: 0.9442\n",
      "Epoch 54/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.1294 - RMSE: 0.9221 - val_loss: 1.1449 - val_RMSE: 0.9435\n",
      "Epoch 55/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1183 - RMSE: 0.9222 - val_loss: 1.1330 - val_RMSE: 0.9422\n",
      "Epoch 56/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1074 - RMSE: 0.9213 - val_loss: 1.1265 - val_RMSE: 0.9458\n",
      "Epoch 57/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0974 - RMSE: 0.9216 - val_loss: 1.1130 - val_RMSE: 0.9418\n",
      "Epoch 58/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0877 - RMSE: 0.9207 - val_loss: 1.1036 - val_RMSE: 0.9413\n",
      "Epoch 59/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0788 - RMSE: 0.9204 - val_loss: 1.1003 - val_RMSE: 0.9465\n",
      "Epoch 60/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.0703 - RMSE: 0.9205 - val_loss: 1.0892 - val_RMSE: 0.9434\n",
      "Epoch 61/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0626 - RMSE: 0.9203 - val_loss: 1.0790 - val_RMSE: 0.9408\n",
      "Epoch 62/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0549 - RMSE: 0.9201 - val_loss: 1.0740 - val_RMSE: 0.9428\n",
      "Epoch 63/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0479 - RMSE: 0.9205 - val_loss: 1.0708 - val_RMSE: 0.9463\n",
      "Epoch 64/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0412 - RMSE: 0.9199 - val_loss: 1.0587 - val_RMSE: 0.9406\n",
      "Epoch 65/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.0350 - RMSE: 0.9198 - val_loss: 1.0536 - val_RMSE: 0.9415\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "result = model.fit(\n",
    "  x=[ratings_train.user_id.values, ratings_train.movie_id.values],\n",
    "  y=ratings_train.rating.values - mu,\n",
    "  epochs=65,\n",
    "  batch_size=512,\n",
    "  validation_data=(\n",
    "    [ratings_test.user_id.values, ratings_test.movie_id.values],\n",
    "    ratings_test.rating.values - mu\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result.history['RMSE'], label=\"Train RMSE\")\n",
    "plt.plot(result.history['val_RMSE'], label=\"Test RMSE\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals: \n",
      "        user_id  movie_id  rating\n",
      "62989      764        28       4\n",
      "5925        86       286       3\n",
      "59050      437       450       3\n",
      "77059      643       685       3\n",
      "81909      654       588       4\n",
      "12645      244       135       4\n",
      "\n",
      "Predictions: \n",
      " [[4.17346  ]\n",
      " [3.837898 ]\n",
      " [2.497438 ]\n",
      " [3.382253 ]\n",
      " [3.831256 ]\n",
      " [4.1608863]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9419615297531404"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "user_ids = ratings_test.user_id.values[0:6]\n",
    "movie_ids = ratings_test.movie_id.values[0:6]\n",
    "predictions = model.predict([user_ids, movie_ids]) + mu\n",
    "print(\"Actuals: \\n\", ratings_test[0:6])\n",
    "print()\n",
    "print(\"Predictions: \\n\", predictions)\n",
    "\n",
    "# 정확도(RMSE)를 계산하는 함수 \n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "user_ids = ratings_test.user_id.values\n",
    "movie_ids = ratings_test.movie_id.values\n",
    "y_pred = model.predict([user_ids, movie_ids]) + mu\n",
    "y_pred = np.ravel(y_pred, order='C')\n",
    "y_true = np.array(ratings_test.rating)\n",
    "\n",
    "RMSE2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 딥러닝 모델에 변수 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정된 부분 1 >>>>>>>>>>\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./dataset/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
    "users = users[['user_id', 'occupation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert occupation(string to integer)\n",
    "occupation = {}\n",
    "def convert_occ(x):\n",
    "    if x in occupation:\n",
    "        return occupation[x]\n",
    "    else:\n",
    "        occupation[x] = len(occupation)\n",
    "        return occupation[x]\n",
    "\n",
    "users['occupation'] = users['occupation'].apply(convert_occ)\n",
    "\n",
    "L = len(occupation)\n",
    "train_occ = pd.merge(ratings_train, users, on='user_id')['occupation']\n",
    "test_occ = pd.merge(ratings_test, users, on='user_id')['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model\n",
    "user = Input(shape=(1, ))\n",
    "item = Input(shape=(1, ))\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)\n",
    "item_bias = Embedding(N, 1, embeddings_regularizer=l2())(item)\n",
    "\n",
    "# Concatenate layers\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation\n",
    "P_embedding = Flatten()(P_embedding)\n",
    "Q_embedding = Flatten()(Q_embedding)\n",
    "user_bias = Flatten()(user_bias)\n",
    "item_bias = Flatten()(item_bias)\n",
    "\n",
    "# 수정된 부분 2 >>>>>>>>>>\n",
    "occ = Input(shape=(1, ))\n",
    "occ_embedding = Embedding(L, 3, embeddings_regularizer=l2())(occ)\n",
    "occ_layer = Flatten()(occ_embedding)\n",
    "R = Concatenate()([P_embedding, Q_embedding, user_bias, item_bias, occ_layer])\n",
    "#<<<<<<<<< 수정된 부분 2\n",
    "\n",
    "# Neural network\n",
    "R = Dense(2048)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(256)(R)\n",
    "R = Activation('linear')(R)\n",
    "R = Dense(1)(R)\n",
    "\n",
    "# 수정된 부분 3 >>>>>>>>>>\n",
    "model = Model(inputs=[user, item, occ], outputs=R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)       (None, 1, 200)       188800      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_13 (Embedding)       (None, 1, 200)       336600      ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_14 (Embedding)       (None, 1, 1)         944         ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)       (None, 1, 1)         1683        ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 1, 3)         63          ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 200)          0           ['embedding_12[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 200)          0           ['embedding_13[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 1)            0           ['embedding_14[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 1)            0           ['embedding_15[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 3)            0           ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 405)          0           ['flatten_6[0][0]',              \n",
      "                                                                  'flatten_7[0][0]',              \n",
      "                                                                  'flatten_8[0][0]',              \n",
      "                                                                  'flatten_9[0][0]',              \n",
      "                                                                  'flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2048)         831488      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 2048)         0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          524544      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 256)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            257         ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,884,379\n",
      "Trainable params: 1,884,379\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#<<<<<<<<< 수정된 부분 3\n",
    "model.compile(\n",
    "  loss=RMSE,\n",
    "  optimizer=SGD(),\n",
    "  #optimizer=Adamax(),\n",
    "  metrics=[RMSE]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 5.4139 - RMSE: 1.1234 - val_loss: 5.2929 - val_RMSE: 1.1282\n",
      "Epoch 2/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 5.1671 - RMSE: 1.1217 - val_loss: 5.0535 - val_RMSE: 1.1265\n",
      "Epoch 3/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 4.9346 - RMSE: 1.1197 - val_loss: 4.8278 - val_RMSE: 1.1251\n",
      "Epoch 4/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 4.7154 - RMSE: 1.1186 - val_loss: 4.6151 - val_RMSE: 1.1237\n",
      "Epoch 5/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 4.5086 - RMSE: 1.1173 - val_loss: 4.4142 - val_RMSE: 1.1220\n",
      "Epoch 6/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 4.3136 - RMSE: 1.1152 - val_loss: 4.2249 - val_RMSE: 1.1204\n",
      "Epoch 7/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 4.1295 - RMSE: 1.1138 - val_loss: 4.0461 - val_RMSE: 1.1187\n",
      "Epoch 8/65\n",
      "147/147 [==============================] - 6s 41ms/step - loss: 3.9557 - RMSE: 1.1118 - val_loss: 3.8774 - val_RMSE: 1.1169\n",
      "Epoch 9/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 3.7916 - RMSE: 1.1097 - val_loss: 3.7181 - val_RMSE: 1.1148\n",
      "Epoch 10/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 3.6367 - RMSE: 1.1076 - val_loss: 3.5676 - val_RMSE: 1.1125\n",
      "Epoch 11/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 3.4903 - RMSE: 1.1051 - val_loss: 3.4253 - val_RMSE: 1.1099\n",
      "Epoch 12/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 3.3517 - RMSE: 1.1024 - val_loss: 3.2905 - val_RMSE: 1.1068\n",
      "Epoch 13/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 3.2205 - RMSE: 1.0993 - val_loss: 3.1630 - val_RMSE: 1.1034\n",
      "Epoch 14/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 3.0962 - RMSE: 1.0955 - val_loss: 3.0421 - val_RMSE: 1.0993\n",
      "Epoch 15/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 2.9783 - RMSE: 1.0907 - val_loss: 2.9274 - val_RMSE: 1.0947\n",
      "Epoch 16/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 2.8663 - RMSE: 1.0856 - val_loss: 2.8183 - val_RMSE: 1.0893\n",
      "Epoch 17/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 2.7598 - RMSE: 1.0796 - val_loss: 2.7145 - val_RMSE: 1.0831\n",
      "Epoch 18/65\n",
      "147/147 [==============================] - 5s 33ms/step - loss: 2.6581 - RMSE: 1.0726 - val_loss: 2.6158 - val_RMSE: 1.0764\n",
      "Epoch 19/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 2.5612 - RMSE: 1.0652 - val_loss: 2.5210 - val_RMSE: 1.0682\n",
      "Epoch 20/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 2.4686 - RMSE: 1.0565 - val_loss: 2.4309 - val_RMSE: 1.0595\n",
      "Epoch 21/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 2.3802 - RMSE: 1.0472 - val_loss: 2.3446 - val_RMSE: 1.0499\n",
      "Epoch 22/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 2.2957 - RMSE: 1.0371 - val_loss: 2.2627 - val_RMSE: 1.0401\n",
      "Epoch 23/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 2.2154 - RMSE: 1.0269 - val_loss: 2.1849 - val_RMSE: 1.0303\n",
      "Epoch 24/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 2.1392 - RMSE: 1.0167 - val_loss: 2.1113 - val_RMSE: 1.0207\n",
      "Epoch 25/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 2.0671 - RMSE: 1.0064 - val_loss: 2.0420 - val_RMSE: 1.0119\n",
      "Epoch 26/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.9992 - RMSE: 0.9977 - val_loss: 1.9767 - val_RMSE: 1.0036\n",
      "Epoch 27/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.9354 - RMSE: 0.9890 - val_loss: 1.9156 - val_RMSE: 0.9962\n",
      "Epoch 28/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.8755 - RMSE: 0.9817 - val_loss: 1.8583 - val_RMSE: 0.9898\n",
      "Epoch 29/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.8194 - RMSE: 0.9749 - val_loss: 1.8047 - val_RMSE: 0.9842\n",
      "Epoch 30/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.7666 - RMSE: 0.9686 - val_loss: 1.7543 - val_RMSE: 0.9791\n",
      "Epoch 31/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.7173 - RMSE: 0.9633 - val_loss: 1.7071 - val_RMSE: 0.9748\n",
      "Epoch 32/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.6709 - RMSE: 0.9588 - val_loss: 1.6629 - val_RMSE: 0.9710\n",
      "Epoch 33/65\n",
      "147/147 [==============================] - 6s 40ms/step - loss: 1.6274 - RMSE: 0.9546 - val_loss: 1.6213 - val_RMSE: 0.9677\n",
      "Epoch 34/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.5865 - RMSE: 0.9510 - val_loss: 1.5824 - val_RMSE: 0.9648\n",
      "Epoch 35/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.5482 - RMSE: 0.9475 - val_loss: 1.5460 - val_RMSE: 0.9624\n",
      "Epoch 36/65\n",
      "147/147 [==============================] - 6s 38ms/step - loss: 1.5121 - RMSE: 0.9447 - val_loss: 1.5117 - val_RMSE: 0.9603\n",
      "Epoch 37/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.4783 - RMSE: 0.9420 - val_loss: 1.4787 - val_RMSE: 0.9577\n",
      "Epoch 38/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.4463 - RMSE: 0.9395 - val_loss: 1.4489 - val_RMSE: 0.9564\n",
      "Epoch 39/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.4165 - RMSE: 0.9376 - val_loss: 1.4195 - val_RMSE: 0.9541\n",
      "Epoch 40/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.3882 - RMSE: 0.9354 - val_loss: 1.3925 - val_RMSE: 0.9526\n",
      "Epoch 41/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.3618 - RMSE: 0.9340 - val_loss: 1.3671 - val_RMSE: 0.9513\n",
      "Epoch 42/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.3368 - RMSE: 0.9323 - val_loss: 1.3435 - val_RMSE: 0.9503\n",
      "Epoch 43/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.3131 - RMSE: 0.9307 - val_loss: 1.3207 - val_RMSE: 0.9490\n",
      "Epoch 44/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.2910 - RMSE: 0.9294 - val_loss: 1.3035 - val_RMSE: 0.9520\n",
      "Epoch 45/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.2703 - RMSE: 0.9282 - val_loss: 1.2794 - val_RMSE: 0.9470\n",
      "Epoch 46/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.2506 - RMSE: 0.9271 - val_loss: 1.2634 - val_RMSE: 0.9490\n",
      "Epoch 47/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 1.2323 - RMSE: 0.9264 - val_loss: 1.2432 - val_RMSE: 0.9458\n",
      "Epoch 48/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.2150 - RMSE: 0.9255 - val_loss: 1.2263 - val_RMSE: 0.9449\n",
      "Epoch 49/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.1986 - RMSE: 0.9247 - val_loss: 1.2117 - val_RMSE: 0.9455\n",
      "Epoch 50/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.1833 - RMSE: 0.9241 - val_loss: 1.1958 - val_RMSE: 0.9439\n",
      "Epoch 51/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.1688 - RMSE: 0.9238 - val_loss: 1.1833 - val_RMSE: 0.9449\n",
      "Epoch 52/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.1549 - RMSE: 0.9226 - val_loss: 1.1689 - val_RMSE: 0.9432\n",
      "Epoch 53/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.1423 - RMSE: 0.9226 - val_loss: 1.1570 - val_RMSE: 0.9433\n",
      "Epoch 54/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.1298 - RMSE: 0.9217 - val_loss: 1.1458 - val_RMSE: 0.9435\n",
      "Epoch 55/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1185 - RMSE: 0.9212 - val_loss: 1.1365 - val_RMSE: 0.9449\n",
      "Epoch 56/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.1078 - RMSE: 0.9212 - val_loss: 1.1231 - val_RMSE: 0.9416\n",
      "Epoch 57/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0979 - RMSE: 0.9210 - val_loss: 1.1147 - val_RMSE: 0.9428\n",
      "Epoch 58/65\n",
      "147/147 [==============================] - 5s 34ms/step - loss: 1.0883 - RMSE: 0.9207 - val_loss: 1.1070 - val_RMSE: 0.9440\n",
      "Epoch 59/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.0795 - RMSE: 0.9207 - val_loss: 1.0957 - val_RMSE: 0.9413\n",
      "Epoch 60/65\n",
      "147/147 [==============================] - 5s 37ms/step - loss: 1.0706 - RMSE: 0.9198 - val_loss: 1.0874 - val_RMSE: 0.9410\n",
      "Epoch 61/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.0628 - RMSE: 0.9205 - val_loss: 1.0798 - val_RMSE: 0.9411\n",
      "Epoch 62/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.0554 - RMSE: 0.9204 - val_loss: 1.0745 - val_RMSE: 0.9429\n",
      "Epoch 63/65\n",
      "147/147 [==============================] - 5s 36ms/step - loss: 1.0483 - RMSE: 0.9199 - val_loss: 1.0688 - val_RMSE: 0.9439\n",
      "Epoch 64/65\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 1.0416 - RMSE: 0.9198 - val_loss: 1.0591 - val_RMSE: 0.9406\n",
      "Epoch 65/65\n",
      "147/147 [==============================] - 6s 39ms/step - loss: 1.0352 - RMSE: 0.9196 - val_loss: 1.0531 - val_RMSE: 0.9406\n"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "result = model.fit(\n",
    "  x=[ratings_train.user_id.values, ratings_train.movie_id.values, train_occ.values],\n",
    "  y=ratings_train.rating.values - mu,\n",
    "  epochs=65,\n",
    "  batch_size=512,\n",
    "  validation_data=(\n",
    "    [ratings_test.user_id.values, ratings_test.movie_id.values, test_occ.values],\n",
    "    ratings_test.rating.values - mu\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot RMSE\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result.history['RMSE'], label=\"Train RMSE\")\n",
    "plt.plot(result.history['val_RMSE'], label=\"Test RMSE\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals: \n",
      "        user_id  movie_id  rating\n",
      "62989      764        28       4\n",
      "5925        86       286       3\n",
      "59050      437       450       3\n",
      "77059      643       685       3\n",
      "81909      654       588       4\n",
      "12645      244       135       4\n",
      "\n",
      "Predictions: \n",
      " [[4.1636386]\n",
      " [3.9213605]\n",
      " [2.4834595]\n",
      " [3.3446496]\n",
      " [3.794316 ]\n",
      " [4.203824 ]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "user_ids = ratings_test.user_id.values[0:6]\n",
    "movie_ids = ratings_test.movie_id.values[0:6]\n",
    "user_occ = test_occ[0:6]\n",
    "predictions = model.predict([user_ids, movie_ids, user_occ]) + mu\n",
    "print(\"Actuals: \\n\", ratings_test[0:6])\n",
    "print()\n",
    "print(\"Predictions: \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9409656895443061"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도(RMSE)를 계산하는 함수 \n",
    "def RMSE2(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "user_ids = ratings_test.user_id.values\n",
    "movie_ids = ratings_test.movie_id.values\n",
    "y_pred = model.predict([user_ids, movie_ids, test_occ]) + mu\n",
    "y_pred = np.ravel(y_pred, order='C')\n",
    "y_true = np.array(ratings_test.rating)\n",
    "\n",
    "RMSE2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 하이브리드 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 하이브리드 추천 시스템의 원리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy recommender 0\n",
    "import random\n",
    "\n",
    "def recommender0(recomm_list):\n",
    "    recommendations = []\n",
    "    for _ in recomm_list:\n",
    "        recommendations.append(random.random() * 4 + 1)\n",
    "    \n",
    "    return np.array(recommendations)\n",
    "\n",
    "# dummy recommender 1\n",
    "def recommender1(recomm_list):\n",
    "    recommendations = []\n",
    "    for _ in recomm_list:\n",
    "        recommendations.append(random.random() * 4 + 1)\n",
    "    \n",
    "    return np.array(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.570196772569366"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get hybrid result\n",
    "weight = [0.8, 0.2]\n",
    "recomm_list = np.array(ratings_test)\n",
    "\n",
    "predictions0 = recommender0(recomm_list)\n",
    "predictions1 = recommender1(recomm_list)\n",
    "\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(recomm_list[:, 2], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 하이브리드 추천 시스템(CF와 MF의 결합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "rating_matrix = ratings_train.pivot(index='user_id', columns='movie_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set 사용자들의 Cosine similarities 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix_dummy = rating_matrix.copy().fillna(0)\n",
    "user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)\n",
    "user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터의 user의 rating 평균과 영화의 평점편차 계산 \n",
    "rating_mean = rating_matrix.mean(axis=1)\n",
    "rating_bias = (rating_matrix.T - rating_mean).T\n",
    "\n",
    "def CF_knn_bias(user_id, movie_id, neighbor_size=0):\n",
    "    if movie_id in rating_bias:\n",
    "        sim_scores = user_similarity[user_id]\n",
    "        movie_ratings = rating_bias[movie_id]\n",
    "        none_rating_idx = movie_ratings[movie_ratings.isnull()].index\n",
    "        movie_ratings = movie_ratings.drop(none_rating_idx)\n",
    "        sim_scores = sim_scores.drop(none_rating_idx)\n",
    "        if neighbor_size == 0:\n",
    "            prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "            prediction = prediction + rating_mean[user_id]\n",
    "        else:\n",
    "            if len(sim_scores) > 1:\n",
    "                neighbor_size = min(neighbor_size, len(sim_scores))\n",
    "                sim_scores = np.array(sim_scores)\n",
    "                movie_ratings = np.array(movie_ratings)\n",
    "                user_idx = np.argsort(sim_scores)\n",
    "                sim_scores = sim_scores[user_idx][-neighbor_size:]\n",
    "                movie_ratings = movie_ratings[user_idx][-neighbor_size:]\n",
    "                prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()\n",
    "                prediction = prediction + rating_mean[user_id]\n",
    "            else:\n",
    "                prediction = rating_mean[user_id]\n",
    "    else:\n",
    "        prediction = rating_mean[user_id]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MF 추천 알고리즘 >>>>>>>>>>>>>>>\n",
    "\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0                    # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set                         # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        prediction = self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "        return prediction\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9675 ; Test RMSE = 0.9821\n",
      "Iteration: 20 ; Train RMSE = 0.9432 ; Test RMSE = 0.9619\n",
      "Iteration: 30 ; Train RMSE = 0.9326 ; Test RMSE = 0.9536\n",
      "Iteration: 40 ; Train RMSE = 0.9265 ; Test RMSE = 0.9491\n",
      "Iteration: 50 ; Train RMSE = 0.9226 ; Test RMSE = 0.9464\n",
      "Iteration: 60 ; Train RMSE = 0.9199 ; Test RMSE = 0.9446\n",
      "Iteration: 70 ; Train RMSE = 0.9177 ; Test RMSE = 0.9434\n",
      "Iteration: 80 ; Train RMSE = 0.9159 ; Test RMSE = 0.9424\n",
      "Iteration: 90 ; Train RMSE = 0.9142 ; Test RMSE = 0.9417\n",
      "Iteration: 100 ; Train RMSE = 0.9123 ; Test RMSE = 0.9409\n",
      "Iteration: 110 ; Train RMSE = 0.9100 ; Test RMSE = 0.9401\n",
      "Iteration: 120 ; Train RMSE = 0.9070 ; Test RMSE = 0.9390\n",
      "Iteration: 130 ; Train RMSE = 0.9026 ; Test RMSE = 0.9375\n",
      "Iteration: 140 ; Train RMSE = 0.8964 ; Test RMSE = 0.9351\n",
      "Iteration: 150 ; Train RMSE = 0.8880 ; Test RMSE = 0.9320\n",
      "Iteration: 160 ; Train RMSE = 0.8773 ; Test RMSE = 0.9283\n",
      "Iteration: 170 ; Train RMSE = 0.8647 ; Test RMSE = 0.9245\n",
      "Iteration: 180 ; Train RMSE = 0.8509 ; Test RMSE = 0.9210\n",
      "Iteration: 190 ; Train RMSE = 0.8357 ; Test RMSE = 0.9179\n",
      "Iteration: 200 ; Train RMSE = 0.8192 ; Test RMSE = 0.9151\n",
      "Iteration: 210 ; Train RMSE = 0.8012 ; Test RMSE = 0.9126\n",
      "Iteration: 220 ; Train RMSE = 0.7818 ; Test RMSE = 0.9106\n",
      "Iteration: 230 ; Train RMSE = 0.7609 ; Test RMSE = 0.9090\n",
      "Iteration: 240 ; Train RMSE = 0.7388 ; Test RMSE = 0.9079\n",
      "Iteration: 250 ; Train RMSE = 0.7158 ; Test RMSE = 0.9073\n"
     ]
    }
   ],
   "source": [
    "# MF클래스 생성 및 학습\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=250, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Hybrid 추천 알고리즘\n",
    "\n",
    "def recommender0(recomm_list, mf):\n",
    "    recommendations = np.array([mf.get_one_prediction(user, movie) for (user, movie) in recomm_list])\n",
    "    return recommendations\n",
    "\n",
    "def recommender1(recomm_list, neighbor_size=0):\n",
    "    recommendations = np.array([CF_knn_bias(user, movie, neighbor_size) for (user, movie) in recomm_list])\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights - 0.00 : 1.00 ; RMSE = 0.9449573\n",
      "Weights - 0.01 : 0.99 ; RMSE = 0.9441236\n",
      "Weights - 0.02 : 0.98 ; RMSE = 0.9432985\n",
      "Weights - 0.03 : 0.97 ; RMSE = 0.9424821\n",
      "Weights - 0.04 : 0.96 ; RMSE = 0.9416744\n",
      "Weights - 0.05 : 0.95 ; RMSE = 0.9408755\n",
      "Weights - 0.06 : 0.94 ; RMSE = 0.9400853\n",
      "Weights - 0.07 : 0.93 ; RMSE = 0.9393039\n",
      "Weights - 0.08 : 0.92 ; RMSE = 0.9385312\n",
      "Weights - 0.09 : 0.91 ; RMSE = 0.9377674\n",
      "Weights - 0.10 : 0.90 ; RMSE = 0.9370124\n",
      "Weights - 0.11 : 0.89 ; RMSE = 0.9362662\n",
      "Weights - 0.12 : 0.88 ; RMSE = 0.9355290\n",
      "Weights - 0.13 : 0.87 ; RMSE = 0.9348006\n",
      "Weights - 0.14 : 0.86 ; RMSE = 0.9340812\n",
      "Weights - 0.15 : 0.85 ; RMSE = 0.9333707\n",
      "Weights - 0.16 : 0.84 ; RMSE = 0.9326691\n",
      "Weights - 0.17 : 0.83 ; RMSE = 0.9319766\n",
      "Weights - 0.18 : 0.82 ; RMSE = 0.9312930\n",
      "Weights - 0.19 : 0.81 ; RMSE = 0.9306185\n",
      "Weights - 0.20 : 0.80 ; RMSE = 0.9299530\n",
      "Weights - 0.21 : 0.79 ; RMSE = 0.9292966\n",
      "Weights - 0.22 : 0.78 ; RMSE = 0.9286492\n",
      "Weights - 0.23 : 0.77 ; RMSE = 0.9280110\n",
      "Weights - 0.24 : 0.76 ; RMSE = 0.9273818\n",
      "Weights - 0.25 : 0.75 ; RMSE = 0.9267618\n",
      "Weights - 0.26 : 0.74 ; RMSE = 0.9261510\n",
      "Weights - 0.27 : 0.73 ; RMSE = 0.9255493\n",
      "Weights - 0.28 : 0.72 ; RMSE = 0.9249568\n",
      "Weights - 0.29 : 0.71 ; RMSE = 0.9243735\n",
      "Weights - 0.30 : 0.70 ; RMSE = 0.9237995\n",
      "Weights - 0.31 : 0.69 ; RMSE = 0.9232346\n",
      "Weights - 0.32 : 0.68 ; RMSE = 0.9226791\n",
      "Weights - 0.33 : 0.67 ; RMSE = 0.9221328\n",
      "Weights - 0.34 : 0.66 ; RMSE = 0.9215958\n",
      "Weights - 0.35 : 0.65 ; RMSE = 0.9210682\n",
      "Weights - 0.36 : 0.64 ; RMSE = 0.9205498\n",
      "Weights - 0.37 : 0.63 ; RMSE = 0.9200408\n",
      "Weights - 0.38 : 0.62 ; RMSE = 0.9195411\n",
      "Weights - 0.39 : 0.61 ; RMSE = 0.9190509\n",
      "Weights - 0.40 : 0.60 ; RMSE = 0.9185700\n",
      "Weights - 0.41 : 0.59 ; RMSE = 0.9180985\n",
      "Weights - 0.42 : 0.58 ; RMSE = 0.9176364\n",
      "Weights - 0.43 : 0.57 ; RMSE = 0.9171837\n",
      "Weights - 0.44 : 0.56 ; RMSE = 0.9167405\n",
      "Weights - 0.45 : 0.55 ; RMSE = 0.9163068\n",
      "Weights - 0.46 : 0.54 ; RMSE = 0.9158825\n",
      "Weights - 0.47 : 0.53 ; RMSE = 0.9154677\n",
      "Weights - 0.48 : 0.52 ; RMSE = 0.9150624\n",
      "Weights - 0.49 : 0.51 ; RMSE = 0.9146666\n",
      "Weights - 0.50 : 0.50 ; RMSE = 0.9142804\n",
      "Weights - 0.51 : 0.49 ; RMSE = 0.9139036\n",
      "Weights - 0.52 : 0.48 ; RMSE = 0.9135364\n",
      "Weights - 0.53 : 0.47 ; RMSE = 0.9131788\n",
      "Weights - 0.54 : 0.46 ; RMSE = 0.9128308\n",
      "Weights - 0.55 : 0.45 ; RMSE = 0.9124923\n",
      "Weights - 0.56 : 0.44 ; RMSE = 0.9121634\n",
      "Weights - 0.57 : 0.43 ; RMSE = 0.9118441\n",
      "Weights - 0.58 : 0.42 ; RMSE = 0.9115344\n",
      "Weights - 0.59 : 0.41 ; RMSE = 0.9112344\n",
      "Weights - 0.60 : 0.40 ; RMSE = 0.9109439\n",
      "Weights - 0.61 : 0.39 ; RMSE = 0.9106632\n",
      "Weights - 0.62 : 0.38 ; RMSE = 0.9103920\n",
      "Weights - 0.63 : 0.37 ; RMSE = 0.9101305\n",
      "Weights - 0.64 : 0.36 ; RMSE = 0.9098787\n",
      "Weights - 0.65 : 0.35 ; RMSE = 0.9096366\n",
      "Weights - 0.66 : 0.34 ; RMSE = 0.9094041\n",
      "Weights - 0.67 : 0.33 ; RMSE = 0.9091813\n",
      "Weights - 0.68 : 0.32 ; RMSE = 0.9089683\n",
      "Weights - 0.69 : 0.31 ; RMSE = 0.9087649\n",
      "Weights - 0.70 : 0.30 ; RMSE = 0.9085712\n",
      "Weights - 0.71 : 0.29 ; RMSE = 0.9083873\n",
      "Weights - 0.72 : 0.28 ; RMSE = 0.9082130\n",
      "Weights - 0.73 : 0.27 ; RMSE = 0.9080485\n",
      "Weights - 0.74 : 0.26 ; RMSE = 0.9078937\n",
      "Weights - 0.75 : 0.25 ; RMSE = 0.9077487\n",
      "Weights - 0.76 : 0.24 ; RMSE = 0.9076134\n",
      "Weights - 0.77 : 0.23 ; RMSE = 0.9074879\n",
      "Weights - 0.78 : 0.22 ; RMSE = 0.9073721\n",
      "Weights - 0.79 : 0.21 ; RMSE = 0.9072660\n",
      "Weights - 0.80 : 0.20 ; RMSE = 0.9071697\n",
      "Weights - 0.81 : 0.19 ; RMSE = 0.9070832\n",
      "Weights - 0.82 : 0.18 ; RMSE = 0.9070064\n",
      "Weights - 0.83 : 0.17 ; RMSE = 0.9069394\n",
      "Weights - 0.84 : 0.16 ; RMSE = 0.9068822\n",
      "Weights - 0.85 : 0.15 ; RMSE = 0.9068347\n",
      "Weights - 0.86 : 0.14 ; RMSE = 0.9067970\n",
      "Weights - 0.87 : 0.13 ; RMSE = 0.9067691\n",
      "Weights - 0.88 : 0.12 ; RMSE = 0.9067509\n",
      "Weights - 0.89 : 0.11 ; RMSE = 0.9067426\n",
      "Weights - 0.90 : 0.10 ; RMSE = 0.9067440\n",
      "Weights - 0.91 : 0.09 ; RMSE = 0.9067551\n",
      "Weights - 0.92 : 0.08 ; RMSE = 0.9067761\n",
      "Weights - 0.93 : 0.07 ; RMSE = 0.9068068\n",
      "Weights - 0.94 : 0.06 ; RMSE = 0.9068473\n",
      "Weights - 0.95 : 0.05 ; RMSE = 0.9068975\n",
      "Weights - 0.96 : 0.04 ; RMSE = 0.9069576\n",
      "Weights - 0.97 : 0.03 ; RMSE = 0.9070274\n",
      "Weights - 0.98 : 0.02 ; RMSE = 0.9071069\n",
      "Weights - 0.99 : 0.01 ; RMSE = 0.9071963\n"
     ]
    }
   ],
   "source": [
    "recomm_list = np.array(ratings_test.iloc[:, [0, 1]])\n",
    "\n",
    "predictions0 = recommender0(recomm_list, mf)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions0)\n",
    "\n",
    "predictions1 = recommender1(recomm_list, 37)\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions1)\n",
    "\n",
    "weight = [0.8, 0.2]\n",
    "predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "RMSE2(ratings_test.iloc[:, 2], predictions)\n",
    "\n",
    "for i in np.arange(0, 1, 0.01):\n",
    "    weight = [i, 1.0 - i]\n",
    "    predictions = predictions0 * weight[0] + predictions1 * weight[1]\n",
    "    print(\"Weights - %.2f : %.2f ; RMSE = %.7f\" % (weight[0], \n",
    "           weight[1], RMSE2(ratings_test.iloc[:, 2], predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 대규모 데이터의 처리를 위한 희소 행렬 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Sparse matrix의 개념과 Python에서의 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Sparse matrix를 추천 알고리즘에 적용하기"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c726b45dd7293eb31a34b8969b40a947eb51be7b196d382e5dff74d4c7ac181"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('saltlux_deep_lecture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
